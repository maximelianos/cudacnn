{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fB1BRldbJfjg"
      },
      "source": [
        "# Convolutional autoencoder for image denoising\n",
        "\n",
        "**Author:** [Santiago L. Valdarrama](https://twitter.com/svpino)<br>\n",
        "**Date created:** 2021/03/01<br>\n",
        "**Last modified:** 2021/03/01<br>\n",
        "**Description:** How to train a deep convolutional autoencoder for image denoising."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjo8q0l4Jfju"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "This example demonstrates how to implement a deep convolutional autoencoder\n",
        "for image denoising, mapping noisy digits images from the MNIST dataset to\n",
        "clean digits images. This implementation is based on an original blog post\n",
        "titled [Building Autoencoders in Keras](https://blog.keras.io/building-autoencoders-in-keras.html)\n",
        "by [Fran√ßois Chollet](https://twitter.com/fchollet)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tS6IpIHqJfjw"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xmth0xhVJfjx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "def preprocess(array):\n",
        "    \"\"\"\n",
        "    Normalizes the supplied array and reshapes it into the appropriate format.\n",
        "    \"\"\"\n",
        "\n",
        "    array = array.astype(\"float32\") / 255.0\n",
        "    array = np.reshape(array, (len(array), 28, 28, 1))\n",
        "    return array\n",
        "\n",
        "\n",
        "def noise(array):\n",
        "    \"\"\"\n",
        "    Adds random noise to each image in the supplied array.\n",
        "    \"\"\"\n",
        "\n",
        "    noise_factor = 0.4\n",
        "    noisy_array = array + noise_factor * np.random.normal(\n",
        "        loc=0.0, scale=1.0, size=array.shape\n",
        "    )\n",
        "\n",
        "    return np.clip(noisy_array, 0.0, 1.0)\n",
        "\n",
        "\n",
        "def display(array1, array2):\n",
        "    \"\"\"\n",
        "    Displays ten random images from each one of the supplied arrays.\n",
        "    \"\"\"\n",
        "\n",
        "    n = 10\n",
        "\n",
        "    indices = np.random.randint(len(array1), size=n)\n",
        "    images1 = array1[indices, :]\n",
        "    images2 = array2[indices, :]\n",
        "\n",
        "    plt.figure(figsize=(20, 4))\n",
        "    for i, (image1, image2) in enumerate(zip(images1, images2)):\n",
        "        ax = plt.subplot(2, n, i + 1)\n",
        "        plt.imshow(image1.reshape(28, 28))\n",
        "        plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "        ax = plt.subplot(2, n, i + 1 + n)\n",
        "        plt.imshow(image2.reshape(28, 28))\n",
        "        plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YE0Yf8InJfj3"
      },
      "source": [
        "## Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEC0ed_SJfj5"
      },
      "outputs": [],
      "source": [
        "# Since we only need images from the dataset to encode and decode, we\n",
        "# won't use the labels.\n",
        "(train_data, _), (test_data, _) = mnist.load_data()\n",
        "\n",
        "# Normalize and reshape the data\n",
        "train_data = preprocess(train_data)\n",
        "test_data = preprocess(test_data)\n",
        "\n",
        "# Create a copy of the data with added noise\n",
        "noisy_train_data = noise(train_data)\n",
        "noisy_test_data = noise(test_data)\n",
        "\n",
        "# Display the train data and a version of it with added noise\n",
        "display(train_data, noisy_train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxP9moAmJfj7"
      },
      "source": [
        "## Build the autoencoder\n",
        "\n",
        "We are going to use the Functional API to build our convolutional autoencoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPYyrD42Jfj-"
      },
      "outputs": [],
      "source": [
        "input = layers.Input(shape=(28, 28, 1))\n",
        "\n",
        "# Simplest architecture\n",
        "# x = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(input)\n",
        "# x = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
        "# x = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
        "# x = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
        "# x = layers.Conv2D(1, (3, 3), activation=\"sigmoid\", padding=\"same\")(x)\n",
        "\n",
        "# Encoder\n",
        "x = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(input)\n",
        "x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
        "x = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
        "x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
        "\n",
        "# Decoder\n",
        "x = layers.Conv2DTranspose(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "x = layers.Conv2DTranspose(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "x = layers.Conv2D(1, (3, 3), activation=\"sigmoid\", padding=\"same\")(x)\n",
        "\n",
        "# Autoencoder\n",
        "autoencoder = Model(input, x)\n",
        "autoencoder.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
        "autoencoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "or3-_I9dJfkL"
      },
      "outputs": [],
      "source": [
        "autoencoder.fit(\n",
        "    x=noisy_train_data,\n",
        "    y=train_data,\n",
        "    epochs=50,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        "    validation_data=(noisy_test_data, test_data),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wODLi6FvJfkM"
      },
      "source": [
        "Let's now predict on the noisy data and display the results of our autoencoder.\n",
        "\n",
        "Notice how the autoencoder does an amazing job at removing the noise from the\n",
        "input images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlwyNV41JfkN"
      },
      "outputs": [],
      "source": [
        "predictions = autoencoder.predict(noisy_test_data)\n",
        "display(noisy_test_data, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save some pictures"
      ],
      "metadata": {
        "id": "c2KENSYHvb-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage import io\n",
        "from skimage.transform import resize\n",
        "print(train_data[1000].shape)\n",
        "\n",
        "io.imsave(\"test.png\", noise(train_data[3000][:, :, 0]))\n",
        "io.imsave(\"test2.png\", noise(resize(train_data[1000][:, :, 0], (256,256))))"
      ],
      "metadata": {
        "id": "tdOQQbdKazUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save model"
      ],
      "metadata": {
        "id": "5R3CN1jd9HkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ouf = open(\"model.txt\", \"w\")\n",
        "for i, layer in enumerate(autoencoder.layers[1:]):\n",
        "    weights = layer.get_weights()\n",
        "    if weights:\n",
        "        for x in weights[0].flatten():\n",
        "            ouf.write( \"{:.10f}\\n\".format(x) )\n",
        "        for x in weights[1].flatten():\n",
        "            ouf.write( \"{:.10f}\\n\".format(x) )\n",
        "        print(weights[0].shape)\n",
        "        print(weights[1].shape)\n",
        "ouf.close()"
      ],
      "metadata": {
        "id": "K-Gqzda6UAEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Look at transposed conv operation"
      ],
      "metadata": {
        "id": "HigKtYCa9J5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = layers.Input(shape=(2, 2, 1))\n",
        "\n",
        "# Encoder\n",
        "x = layers.Conv2DTranspose(1, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(input)\n",
        "\n",
        "# Autoencoder\n",
        "m = Model(input, x)\n",
        "m.summary()"
      ],
      "metadata": {
        "id": "jovaahS3mmnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = np.array(\n",
        "    [\n",
        "      [10, 2, 3],\n",
        "     [2, 3, 4],\n",
        "     [3, 4, 5]\n",
        "    ]\n",
        ").reshape((3, 3, 1, 1))\n",
        "b = np.array([0])\n",
        "m.set_weights([w, b])"
      ],
      "metadata": {
        "id": "K8jRK_YynnFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m.layers[1].get_weights()[0]"
      ],
      "metadata": {
        "id": "ikLYhe3rnCkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = np.array([\n",
        "                [1, 2],\n",
        "                [3, 4],\n",
        "]).reshape(1, 2, 2, 1)\n",
        "res = m.predict(inp)"
      ],
      "metadata": {
        "id": "oUinsV2Ln-4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res.reshape((4, 4))"
      ],
      "metadata": {
        "id": "xCnuod1zoX_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Look at conv operation"
      ],
      "metadata": {
        "id": "SDaYudEB9OS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = layers.Input(shape=(3, 3, 1))\n",
        "\n",
        "# Encoder\n",
        "x = layers.Conv2D(1, (3, 3), activation=\"relu\", padding=\"same\")(input)\n",
        "\n",
        "# Autoencoder\n",
        "m = Model(input, x)\n",
        "m.summary()"
      ],
      "metadata": {
        "id": "X8Ea-Ju1yrhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = np.array(\n",
        "    [\n",
        "      [1, 2, 3],\n",
        "     [4, 5, 6],\n",
        "     [7, 8, 9]\n",
        "    ]\n",
        ").reshape((3, 3, 1, 1))\n",
        "b = np.array([0])\n",
        "m.set_weights([w, b])"
      ],
      "metadata": {
        "id": "VrKwImkCzeas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m.layers[1].get_weights()[0]"
      ],
      "metadata": {
        "id": "EsVD8bZ-0vUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = np.array([\n",
        "                [1, 0, 0],\n",
        "                [0, 0, 1],\n",
        "                [0, 1, 0]\n",
        "]).reshape(1, 3, 3, 1)\n",
        "res = m.predict(inp)"
      ],
      "metadata": {
        "id": "2QD94VVlz3qE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res.reshape((3, 3))"
      ],
      "metadata": {
        "id": "YGY0jHB4z72x"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of autoencoder",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}